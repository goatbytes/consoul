{
  "created_at": "2025-11-15T00:46:08.593267",
  "updated_at": "2025-11-20T05:44:44.129417Z",
  "id": "SOUL-114",
  "uuid": "8fc97392-ca58-4c4d-a2d2-06d0ebc54b60",
  "title": "Add multimodal message formatting for vision-capable providers",
  "description": "**As a** Consoul developer\n**I want** provider-specific multimodal message formatting utilities\n**So that** image content is correctly structured for Claude, OpenAI, and Gemini APIs\n\n**Context:**\nEach provider has different message format requirements for vision/multimodal inputs:\n- **Anthropic**: Content blocks with type=\"image\", source={type=\"base64\", media_type, data}\n- **OpenAI**: HumanMessage with type=\"image_url\", image_url={url: \"data:image/jpeg;base64,...\"}\n- **Google**: Content array with image objects (similar to OpenAI)\n\nThis ticket implements the formatting layer that converts our internal representation (query + base64 images) into provider-specific message structures.\n\n**Technical Notes:**\n- src/consoul/ai/multimodal.py - New module\n- Create helper functions per provider (format_anthropic_vision, format_openai_vision, etc.)\n- Use LangChain message types (HumanMessage, etc.)\n- Support multiple images in single message\n- Handle MIME type detection (image/jpeg, image/png, image/gif, image/webp)\n- Reference LangChain docs: https://python.langchain.com/docs/how_to/multimodal_inputs/\n- Consider Files API for Anthropic (optional, future enhancement)\n\n**Acceptance Criteria:**\n\n**Given** I have a query and base64-encoded JPEG image\n**When** I call format_anthropic_vision(query, [(path, base64_data)])\n**Then** I get proper Anthropic content blocks structure\n\n**Given** I have multiple PNG images\n**When** I call format_openai_vision(query, images)\n**Then** I get HumanMessage with multiple image_url content blocks\n\n**Given** I provide a WebP image\n**When** MIME type is detected\n**Then** it's correctly set as image/webp in the message\n\n**Given** I call format_vision() with provider=\"anthropic\"\n**When** provider is detected\n**Then** the correct formatting function is automatically selected\n\n**Testing Considerations:**\n- Test each provider format separately\n- Verify LangChain message structure validity\n- Test MIME type detection accuracy\n- Test multiple images in single message\n- Mock provider responses to ensure format works\n- Test with actual small images in integration tests\n\n**Implementation Hints:**\n```python\nfrom langchain_core.messages import HumanMessage\nfrom consoul.config.models import Provider\n\ndef format_anthropic_vision(\n    query: str, \n    images: list[tuple[str, str]]  # [(path, base64_data), ...]\n) -> dict:\n    \"\"\"Format vision message for Anthropic Claude.\"\"\"\n    content = [{\"type\": \"text\", \"text\": query}]\n    \n    for path, base64_data in images:\n        mime_type = _detect_mime_type(path)\n        content.append({\n            \"type\": \"image\",\n            \"source\": {\n                \"type\": \"base64\",\n                \"media_type\": mime_type,\n                \"data\": base64_data\n            }\n        })\n    \n    return {\"role\": \"user\", \"content\": content}\n\ndef format_openai_vision(query: str, images: list[tuple[str, str]]) -> HumanMessage:\n    \"\"\"Format vision message for OpenAI GPT-4V.\"\"\"\n    content = [{\"type\": \"text\", \"text\": query}]\n    \n    for path, base64_data in images:\n        mime_type = _detect_mime_type(path)\n        content.append({\n            \"type\": \"image_url\",\n            \"image_url\": {\n                \"url\": f\"data:{mime_type};base64,{base64_data}\"\n            }\n        })\n    \n    return HumanMessage(content=content)\n\ndef format_vision_message(\n    provider: Provider,\n    query: str,\n    images: list[tuple[str, str]]\n) -> HumanMessage | dict:\n    \"\"\"Auto-select provider-specific formatting.\"\"\"\n    formatters = {\n        Provider.ANTHROPIC: format_anthropic_vision,\n        Provider.OPENAI: format_openai_vision,\n        Provider.GOOGLE: format_google_vision,\n    }\n    return formatters[provider](query, images)\n```\n\nFiles to create:\n- src/consoul/ai/multimodal.py\n- tests/ai/test_multimodal.py\n\nDependencies: SOUL-113 (core tool must provide base64 images)",
  "status": "done",
  "type": "task",
  "priority": "high",
  "labels": [
    "ai",
    "providers",
    "enhancement"
  ],
  "assignee": "jared@goatbytes.io",
  "reporter": "jared@goatbytes.io",
  "epic_id": "EPIC-007",
  "blocked_by": [],
  "blocks": [],
  "comments": [],
  "attachments": [],
  "attachment_count": 0,
  "comment_count": 0,
  "story_points": 3,
  "order": 0,
  "custom_fields": {},
  "_archive_metadata": {
    "archived_at": "2025-12-03T15:09:09.698252",
    "archived_from_status": "done",
    "archived_by": "gira-cli"
  }
}