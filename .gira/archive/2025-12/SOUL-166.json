{
  "created_at": "2025-11-26T00:50:55.532956",
  "updated_at": "2025-11-26T17:52:57.778548Z",
  "id": "SOUL-166",
  "uuid": "1341db8c-9e8b-4af4-b047-8c20792f03a5",
  "title": "Create ChatSession class for stateful CLI conversations",
  "description": "**As a** Consoul user\n**I want** a stateful chat session in CLI mode\n**So that** I can have multi-turn conversations with context retention\n\n**Context:**\nThe consoul chat command needs a ChatSession class to manage conversation state, similar to how ConsoulApp manages TUI conversations. This class will:\n- Manage ConversationHistory\n- Initialize chat model from config\n- Handle streaming responses\n- Persist conversation if configured\n- Provide clean interface for CLI chat loop\n\nResearch shows that existing components can be reused:\n- src/consoul/ai/history.py - ConversationHistory class already exists\n- src/consoul/ai/streaming.py - stream_response() already implemented\n- src/consoul/ai/providers.py - get_chat_model() available\n- src/consoul/tui/app.py:500-600 - Similar initialization patterns\n\n**Technical Notes:**\n- Create src/consoul/cli/chat_session.py\n- Use ConversationHistory for message management\n- Initialize from ConsoulConfig (same as TUI)\n- Support streaming via stream_response()\n- Handle tool calls if tools are enabled\n- Persist to SQLite if config.persist_history is True\n- Clean session management (enter/exit context)\n- Error handling for API failures, rate limits\n- Interrupt handling (Ctrl+C) to stop streaming\n\n**Acceptance Criteria:**\n\n**Given** I create a ChatSession with a config\n**When** the session is initialized\n**Then** chat model is loaded and conversation history is ready\n\n**Given** I send a message via session.send()\n**When** streaming is enabled\n**Then** tokens stream to console in real-time using Rich\n\n**Given** conversation history exists\n**When** I send subsequent messages\n**Then** previous context is included in API calls\n\n**Given** persist_history is True in config\n**When** session exits\n**Then** conversation is saved to SQLite database\n\n**Given** user presses Ctrl+C during streaming\n**When** interrupt signal is received\n**Then** streaming stops gracefully without error\n\n**Testing Considerations:**\n- Mock LangChain model responses\n- Test with/without persistence\n- Test with/without streaming\n- Test interrupt handling\n- Test error scenarios (API down, rate limit)\n- Verify token counting works\n- Test with different providers\n\n**Implementation Hints:**\n```python\nclass ChatSession:\n    def __init__(self, config: ConsoulConfig):\n        self.config = config\n        self.model = get_chat_model(config)\n        self.history = ConversationHistory(\n            config.current_model,\n            persist=config.persist_history\n        )\n        self.console = Console()\n    \n    def send(self, message: str) -> str:\n        # Add user message to history\n        # Stream response\n        # Add assistant response to history\n        # Return full response\n    \n    def __enter__(self):\n        return self\n    \n    def __exit__(self, *args):\n        # Cleanup, save if needed\n```\n\nReference TUI app initialization: src/consoul/tui/app.py:500-600\nReference streaming: src/consoul/ai/streaming.py:32-80",
  "status": "done",
  "type": "feature",
  "priority": "high",
  "labels": [
    "cli",
    "ai",
    "core",
    "enhancement"
  ],
  "assignee": "jared@goatbytes.io",
  "reporter": "jared@goatbytes.io",
  "blocked_by": [],
  "blocks": [],
  "comments": [],
  "attachments": [],
  "attachment_count": 0,
  "comment_count": 0,
  "story_points": 5,
  "order": 0,
  "custom_fields": {},
  "_archive_metadata": {
    "archived_at": "2025-12-03T15:09:10.614915",
    "archived_from_status": "done",
    "archived_by": "gira-cli"
  }
}