{
  "created_at": "2025-12-02T18:07:44.508859",
  "updated_at": "2025-12-03T23:08:50.354306Z",
  "id": "SOUL-216",
  "uuid": "f036cb4b-dc3b-486d-be9d-550b8d3c504b",
  "title": "Fix AI provider mock and initialization tests",
  "description": "**As a** Consoul developer\n**I want** AI provider initialization tests to pass with proper mocking\n**So that** we can test provider logic without making real API calls\n\n**Context:**\n35 tests in tests/ai/test_providers.py are failing because real ChatModel instances are being created instead of mocks. Tests are asserting equality with MagicMock objects but getting actual ChatOpenAI/ChatGoogle/etc instances.\n\nRoot cause: get_chat_model() function is not being properly mocked, resulting in actual provider initialization.\n\n**Technical Notes:**\n- tests/ai/test_providers.py - Provider tests\n- src/consoul/ai/providers.py:980-1114 - get_chat_model implementation\n- Mock assertions failing: ChatOpenAI(...) == <MagicMock name='...' id='...'>\n\n**Acceptance Criteria:**\n\n**Given** provider tests are run\n**When** get_chat_model is called\n**Then** it should return mocked instances, not real providers\n\n**Failing Test Categories:**\n- OpenAI provider tests (~15 failures)\n- Google provider tests (~3 failures)\n- HuggingFace provider tests (~12 failures)  \n- LlamaCpp provider tests (~2 failures)\n- Error handling tests (~3 failures)\n\n**Testing Considerations:**\n- Ensure mocks are applied before get_chat_model calls\n- Verify no real API calls are made during tests\n- Test with various provider configurations\n\n**Implementation Hints:**\n- Review mock setup in test fixtures\n- Use @patch decorators at correct scope\n- Mock init_chat_model or ChatProvider classes\n- Verify mock.assert_called_with() arguments match",
  "status": "done",
  "type": "bug",
  "priority": "high",
  "labels": [
    "testing",
    "bug",
    "ai",
    "providers"
  ],
  "assignee": "jared@goatbytes.io",
  "reporter": "jared@goatbytes.io",
  "parent_id": "SOUL-214",
  "blocked_by": [],
  "blocks": [],
  "comments": [
    {
      "created_at": "2025-12-02T18:20:55.231945",
      "updated_at": "2025-12-02T18:20:55.231946",
      "id": "20251202182055-ccc03f9c",
      "ticket_id": "SOUL-216",
      "author": "jared@goatbytes.io",
      "content": "Fixed 18 of 35 failing tests in tests/ai/test_providers.py (51% improvement).\n\n## Root Cause\nReal ChatModel instances were being created instead of mocks because the tests were mocking `consoul.ai.providers.init_chat_model`, but:\n1. **OpenAI provider** directly imports and instantiates `langchain_openai.ChatOpenAI` (line 1673-1690)\n2. **Other providers** use `init_chat_model` as expected\n\nThe mock decorators were targeting the wrong import paths for OpenAI tests.\n\n## Changes Made\n- \u2705 Fixed 15 OpenAI tests by mocking `langchain_openai.ChatOpenAI` instead of `init_chat_model`\n- \u2705 Fixed 1 Google test by correcting assertion (model_provider should be \"google_genai\")  \n- \u2705 Fixed 2 error handling tests by using correct mock target\n- \u2705 All OpenAI tests now properly verify stream_options in model_kwargs\n\n## Test Results\n- **Before**: 35 failures, 73 passes (68% pass rate)\n- **After**: 17 failures, 91 passes (84% pass rate)\n- **Fixed**: 18 tests (51% of originally failing tests)\n\n## Remaining Issues (17 tests)\n1. **10 HuggingFace tests**: Already have mocks but need provider-specific handling\n2. **2 OpenAI error tests**: Need error handling in OpenAI code path  \n3. **3 Google provider tests**: TestGoogleProvider class needs updates\n4. **2 LlamaCpp tests**: Need ChatLlamaCpp mocking\n\n## Commit\n76d3d58 - fix(SOUL-216): fix AI provider mock and initialization tests",
      "edited": false,
      "edit_count": 0,
      "is_ai_generated": false,
      "attachments": [],
      "attachment_count": 0
    },
    {
      "created_at": "2025-12-02T20:02:31.036089",
      "updated_at": "2025-12-02T20:02:31.036090",
      "id": "20251202200231-09d8f034",
      "ticket_id": "SOUL-216",
      "author": "jared@goatbytes.io",
      "content": "Fixed all remaining 17 failing tests:\n\n**HuggingFace Tests (10 fixed):**\n- Corrected mock patch paths from langchain_huggingface submodules to langchain_huggingface top-level imports\n- All HuggingFace provider tests now pass (API, local, quantization, etc.)\n\n**Error Handling Tests (2 fixed):**\n- Added try-except blocks around OpenAI ChatOpenAI initialization\n- Properly catches ImportError and ValueError, raising appropriate custom exceptions\n- Both error handling tests pass\n\n**Google Provider Tests (3 fixed):**\n- Updated test assertions to expect 'google_genai' instead of 'google' (correct LangChain provider name)\n- Added mock for get_api_key in missing API key test\n- All Google provider tests pass\n\n**LlamaCpp Provider Tests (2 fixed):**\n- Corrected mock patch path to langchain_community.chat_models.ChatLlamaCpp\n- Both LlamaCpp tests pass\n\n**Final Results:**\n- All 108 provider tests passing (up from 91)\n- 100% of valid tests passing\n- No tests removed - all were fixable\n- Test coverage improved from ~52% to 100% in TestGetChatModel",
      "edited": false,
      "edit_count": 0,
      "is_ai_generated": false,
      "attachments": [],
      "attachment_count": 0
    }
  ],
  "attachments": [],
  "attachment_count": 0,
  "comment_count": 2,
  "story_points": 5,
  "order": 0,
  "custom_fields": {},
  "_archive_metadata": {
    "archived_at": "2025-12-03T15:09:09.985920",
    "archived_from_status": "done",
    "archived_by": "gira-cli"
  }
}