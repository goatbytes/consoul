{
  "created_at": "2025-12-11T16:28:21.564240",
  "updated_at": "2025-12-15T17:02:35.352252Z",
  "id": "SOUL-264",
  "uuid": "6cee65eb-a649-4a07-91a6-3cb296019fb8",
  "title": "Fix SDK temperature parameter being ignored in model initialization",
  "description": "**As a** Consoul SDK user\n**I want** the temperature parameter to be applied when I create a Consoul instance\n**So that** I can control the model's creativity/randomness as expected\n\n**Context:**\nWhen users create a Consoul instance with a custom temperature parameter:\n\n```python\nconsole = Consoul(temperature=0.7)\n```\n\nThe temperature value is validated (lines 220-223) and stored in `self.temperature` (line 273), but it is **never actually passed** to the model when calling `get_chat_model()` (lines 258-259, 267-269). This means the model uses its default temperature instead, breaking the API contract.\n\nThe bug was discovered during a code review of the SDK implementation in src/consoul/sdk.py.\n\n**Technical Notes:**\n- Bug location: `src/consoul/sdk.py:258-259, 267-269`\n- The `get_chat_model()` function (in `src/consoul/ai/providers.py:963-1200`) accepts `**kwargs` including `temperature`\n- When a string model name is passed, `get_chat_model()` extracts temperature from kwargs (line 1031) and uses it to build the appropriate ModelConfig\n- The SDK __init__ validates and stores temperature but doesn't pass it through\n- Temperature is correctly exposed in the `settings` property (line 669) but not actually used\n\n**Root Cause:**\nIn `Consoul.__init__()`, when calling `get_chat_model()`:\n\n```python\n# Lines 258-259 (with model override)\nself.model = get_chat_model(\n    model, config=self.config, api_key=api_key_secret\n)\n\n# Lines 267-269 (without model override)\nself.model = get_chat_model(\n    self.config.current_model, config=self.config, api_key=api_key_secret\n)\n```\n\nNeither call passes `temperature=self.temperature` to `get_chat_model()`.\n\n**Acceptance Criteria:**\n\n**Given** I create a Consoul instance with temperature=0.2\n**When** I check the actual model temperature used\n**Then** the model should use temperature 0.2, not the default 0.7/1.0\n\n**Given** I create a Consoul instance without specifying temperature\n**When** I check the model temperature\n**Then** the model should use the config's default temperature\n\n**Given** I create a Consoul instance with temperature=2.0 (max)\n**When** I make a request\n**Then** the model should use maximum temperature (most creative)\n\n**Given** I create a Consoul instance with temperature=0.0 (min)\n**When** I make a request\n**Then** the model should use minimum temperature (most deterministic)\n\n**Testing Considerations:**\n- Add unit test that mocks `get_chat_model` and verifies temperature is passed\n- Add integration test that creates Consoul(temperature=0.1) and verifies low randomness\n- Add integration test that creates Consoul(temperature=1.5) and verifies high randomness\n- Test with different providers (OpenAI, Anthropic, Google)\n- Verify temperature=None uses provider's default\n- Test that settings property reflects the actual temperature used\n\n**Implementation Hints:**\n\nFix in `src/consoul/sdk.py` lines 258-259 and 267-269:\n\n```python\n# Option 1: Pass temperature if specified (RECOMMENDED)\nkwargs = {}\nif self.temperature is not None:\n    kwargs[\"temperature\"] = self.temperature\n\nif model:\n    self.model = get_chat_model(\n        model, config=self.config, api_key=api_key_secret, **kwargs\n    )\nelse:\n    self.model = get_chat_model(\n        self.config.current_model, config=self.config, api_key=api_key_secret, **kwargs\n    )\n\n# Option 2: Always pass temperature (simpler but may override config defaults)\nif model:\n    self.model = get_chat_model(\n        model, \n        config=self.config, \n        api_key=api_key_secret,\n        temperature=self.temperature if self.temperature is not None else 0.7\n    )\n```\n\n**Recommendation:** Use Option 1 to preserve config defaults when temperature is not explicitly specified.\n\n**Impact Analysis:**\n- **Severity**: High - API contract is broken, users expect temperature to work\n- **Affected Users**: Anyone using SDK with custom temperature parameter\n- **Workaround**: None - users cannot currently control temperature via SDK\n- **Breaking Change**: No - this is a bug fix that makes the API work as documented\n- **Related Code**: TUI app.py may have similar issue (needs verification)\n\n**References:**\n- `src/consoul/sdk.py:219-223` - Temperature validation\n- `src/consoul/sdk.py:273` - Temperature storage\n- `src/consoul/sdk.py:258-259, 267-269` - get_chat_model calls (bug location)\n- `src/consoul/ai/providers.py:1031` - get_chat_model temperature extraction\n- `src/consoul/config/models.py:109-114` - BaseModelConfig.temperature field",
  "status": "done",
  "type": "bug",
  "priority": "high",
  "labels": [
    "bug",
    "sdk",
    "ai",
    "high-impact"
  ],
  "assignee": "jared@goatbytes.io",
  "reporter": "jared@goatbytes.io",
  "blocked_by": [],
  "blocks": [],
  "comments": [],
  "attachments": [],
  "attachment_count": 0,
  "comment_count": 0,
  "story_points": 2,
  "order": 0,
  "custom_fields": {},
  "_archive_metadata": {
    "archived_at": "2025-12-16T03:35:59.989642+00:00",
    "archived_from_status": "done",
    "archived_by": "gira-cli"
  }
}