{
  "created_at": "2025-12-31T05:23:04.489711Z",
  "updated_at": "2026-01-01T02:34:08.258375Z",
  "id": "SOUL-344",
  "uuid": "9c3728de-5be0-47fc-9f63-6c7dca0fbea8",
  "_version": 2,
  "title": "Document connection pooling and performance tuning",
  "description": "**As a** DevOps engineer optimizing Consoul performance\n**I want** comprehensive documentation on connection pooling and tuning parameters\n**So that** I can configure the server for optimal performance under load\n\n**Context:**\nConsoul uses several connection pools and has various tuning parameters that affect performance:\n- Redis connection pool (rate limiting, session storage)\n- HTTP connection limits (LLM provider calls)\n- WebSocket connection management\n- Thread pool sizing for blocking operations\n\nThese are currently undocumented for production tuning.\n\n**Technical Notes:**\n- Redis connections: `src/consoul/server/factory.py` (session store, rate limiter)\n- Rate limiter Redis: slowapi with socket timeouts (lines 107-108)\n- Session Redis: redis-py client with default pool\n- WebSocket manager: `src/consoul/server/endpoints/websocket.py` (lines 68-106)\n- Thread pool: `asyncio.to_thread()` for blocking Redis/LLM calls\n\n**Documentation Sections:**\n\n**1. Redis Connection Pool**\n```python\n# Default redis-py pool settings\n# max_connections: 2^31 (effectively unlimited)\n# socket_timeout: None (blocking)\n# socket_connect_timeout: None (blocking)\n\n# Recommended production settings\nimport redis\npool = redis.ConnectionPool.from_url(\n    \"redis://localhost:6379\",\n    max_connections=100,\n    socket_timeout=5.0,\n    socket_connect_timeout=2.0,\n    retry_on_timeout=True,\n)\n```\n\nEnvironment variables:\n- `CONSOUL_REDIS_MAX_CONNECTIONS=100`\n- `CONSOUL_REDIS_SOCKET_TIMEOUT=5.0`\n- `CONSOUL_REDIS_CONNECT_TIMEOUT=2.0`\n\n**2. HTTP Connection Limits (LLM Providers)**\n```python\n# httpx/aiohttp default connection pool\n# Most LLM SDKs use these internally\n# OpenAI: 100 connections per host\n# Anthropic: similar defaults\n\n# Tune via environment\nHTTPX_MAX_CONNECTIONS=100\nHTTPX_MAX_KEEPALIVE_CONNECTIONS=20\n```\n\n**3. WebSocket Connection Limits**\n```python\n# Current: No hard limit\n# Recommended: Configure at load balancer level\n# NGINX: worker_connections, proxy_max_temp_file_size\n# Kubernetes: resource limits, HPA\n\n# Consoul-level config (proposed)\nCONSOUL_MAX_WEBSOCKET_CONNECTIONS=10000\nCONSOUL_WEBSOCKET_IDLE_TIMEOUT=300\n```\n\n**4. Thread Pool Sizing**\n```python\n# asyncio.to_thread() uses ThreadPoolExecutor\n# Default: min(32, os.cpu_count() + 4)\n\n# For I/O-heavy workloads (Redis, LLM calls)\nimport asyncio\nasyncio.get_event_loop().set_default_executor(\n    ThreadPoolExecutor(max_workers=100)\n)\n```\n\n**5. Uvicorn Worker Configuration**\n```bash\n# Production settings\nuvicorn consoul.server:create_server \\\n  --workers 4 \\                    # CPU cores\n  --limit-concurrency 1000 \\       # Max concurrent connections\n  --timeout-keep-alive 30 \\        # Keep-alive timeout\n  --backlog 2048                   # Connection queue size\n```\n\n**6. Recommended Production Settings**\nCreate example `docker-compose.yml` and environment file with tuned settings.\n\n**Acceptance Criteria:**\n\n**Given** documentation for Redis connection pool\n**When** an operator needs to tune for high throughput\n**Then** specific settings and environment variables are provided\n\n**Given** LLM provider connection documentation\n**When** dealing with rate limiting from providers\n**Then** connection pool tuning options are explained\n\n**Given** WebSocket connection documentation\n**When** scaling to many concurrent connections\n**Then** limits and tuning at multiple levels are explained\n\n**Given** complete tuning documentation\n**When** deploying to production\n**Then** a ready-to-use configuration example is available\n\n**Testing Considerations:**\n- Verify documented settings work as described\n- Load test with different configurations\n- Measure connection pool metrics under load\n- Document baseline performance numbers\n\n**Implementation Hints:**\n- Create `docs/deployment/performance-tuning.md`\n- Include ASCII diagrams of connection flow\n- Reference Prometheus metrics for monitoring\n- Add example docker-compose with tuned settings\n- Include Kubernetes resource recommendations\n- Cross-reference with load testing guide",
  "status": "done",
  "type": "task",
  "priority": "medium",
  "labels": [
    "documentation",
    "performance",
    "server",
    "operations"
  ],
  "assignee": "jared@goatbytes.io",
  "reporter": "jared@goatbytes.io",
  "epic_id": "EPIC-021",
  "blocked_by": [],
  "blocks": [],
  "comments": [],
  "attachments": [],
  "attachment_count": 0,
  "comment_count": 0,
  "story_points": 3,
  "order": 0,
  "custom_fields": {},
  "_archive_metadata": {
    "archived_at": "2026-01-01T02:34:17.779572+00:00",
    "archived_from_status": "done",
    "archived_by": "gira-cli"
  }
}