{
  "created_at": "2025-12-07T11:46:48.022099",
  "updated_at": "2025-12-16T06:16:39.538850Z",
  "id": "SOUL-232",
  "uuid": "cc127062-5acc-477b-8bcc-cb4ea2e2ec31",
  "title": "Integrate LiteLLM model registry for automatic token limit updates",
  "description": "**As a** Consoul maintainer\n**I want** to automatically fetch model token limits from a community-maintained registry\n**So that** we don't need manual code updates for every new model release\n\n**Context:**\nChatGPT conversation (.local/convo.txt) confirms there's no official API to get context window sizes from any provider (OpenAI, Anthropic, Google). Our current solution uses:\n1. Hardcoded MODEL_TOKEN_LIMITS dictionary (requires manual updates)\n2. Pattern-based intelligent defaults (provides fallback for new models)\n3. Ollama API queries (automatic for Ollama models)\n4. LlamaCpp extraction (automatic for GGUF models)\n\n**Proposed Solution:**\nUse LiteLLM's community-maintained JSON file as primary source:\nhttps://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n\n**Implementation Plan:**\n1. Fetch LiteLLM JSON on startup or periodically (with local cache + TTL)\n2. Merge with hardcoded MODEL_TOKEN_LIMITS (hardcoded takes precedence)\n3. Use pattern-based defaults as final fallback\n4. Add admin command to force-refresh the cache\n\n**Benefits:**\n- Automatic updates for new OpenAI/Anthropic/Google models\n- Community-maintained (1000+ contributors)\n- Includes pricing data too (useful for cost tracking)\n- Still allows local overrides via MODEL_TOKEN_LIMITS\n\n**Trade-offs:**\n- External dependency (mitigated by local cache)\n- Startup network request (mitigated by cache + lazy loading)\n- Extra complexity (minimal - ~100 LOC)\n\n**Files to Modify:**\n- src/consoul/ai/context.py - Add registry fetch/merge logic\n- Add src/consoul/ai/model_registry.py - Registry management\n- tests/ai/test_context.py - Add registry tests\n\n**References:**\n- LiteLLM JSON: https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n- ChatGPT conversation: .local/convo.txt\n- Related: Pattern-based defaults (commit c1bc176)",
  "status": "backlog",
  "type": "feature",
  "priority": "low",
  "labels": [],
  "assignee": "jared@goatbytes.io",
  "reporter": "jared@goatbytes.io",
  "blocked_by": [],
  "blocks": [],
  "comments": [],
  "attachments": [],
  "attachment_count": 0,
  "comment_count": 0,
  "order": 0,
  "custom_fields": {}
}