{
  "created_at": "2025-11-26T00:52:42.294076",
  "updated_at": "2025-11-26T17:52:57.778067Z",
  "id": "SOUL-170",
  "uuid": "f42d3539-5adf-499b-9745-1a9ea0ad642c",
  "title": "Implement CLI chat command with streaming and history",
  "description": "**As a** Consoul user\n**I want** an interactive CLI chat command like Claude Code\n**So that** I can have AI conversations without launching the full TUI\n\n**Context:**\nCurrently consoul chat is a placeholder showing Coming Soon!. This ticket implements the full CLI chat experience with:\n- Streaming token-by-token responses\n- Conversation history with context\n- Rich markdown rendering\n- Enhanced input with prompt_toolkit\n- Tool call support\n- Graceful error handling\n- Session persistence\n\nThis provides a lightweight alternative to TUI for users who prefer traditional CLI.\n\nSimilar tools reference:\n- Claude Code: Streaming, markdown, tool approval\n- aider: Chat loop with file editing\n- llm (Simon Willison): Simple chat with history\n\n**Technical Notes:**\n- src/consoul/__main__.py:118-127 - Replace placeholder implementation\n- Use ChatSession class (SOUL-166) for state management\n- Integrate prompt_toolkit (SOUL-168) for input\n- Use Rich markdown (SOUL-167) for output\n- Handle tool calls (SOUL-169) if tools enabled\n- Support all CLI options: --model, --temperature, --profile, etc.\n- Load config from ConsoulConfig\n- Handle Ctrl+C gracefully (cancel streaming, return to prompt)\n- Handle Ctrl+D or exit command to quit\n- Show conversation stats on exit (messages, tokens, cost if tracked)\n\n**Acceptance Criteria:**\n\n**Given** I run consoul chat\n**When** chat initializes\n**Then** welcome message shows active profile and model\n\n**Given** I am in chat mode\n**When** I type a message and press Enter\n**Then** response streams token-by-token with markdown formatting\n\n**Given** I have previous messages in the conversation\n**When** I send a new message\n**Then** AI uses full conversation context\n\n**Given** I press up arrow\n**When** navigating input history\n**Then** previous messages appear\n\n**Given** AI response is streaming\n**When** I press Ctrl+C\n**Then** streaming stops and I return to input prompt\n\n**Given** I type exit or press Ctrl+D\n**When** ending the session\n**Then** conversation stats are shown and session exits cleanly\n\n**Given** persist_history is True in config\n**When** session ends\n**Then** conversation is saved to database\n\n**Given** tools are enabled\n**When** AI requests tool execution\n**Then** tool call is displayed and I can approve/deny\n\n**Given** I use --model flag\n**When** starting chat: consoul chat --model gpt-4o\n**Then** specified model is used instead of config default\n\n**Testing Considerations:**\n- Test basic chat loop (send/receive)\n- Test streaming responses\n- Test history navigation\n- Test exit conditions (exit, quit, Ctrl+D, Ctrl+C)\n- Test with different models and providers\n- Test with/without tools\n- Test with/without persistence\n- Test error handling (API down, invalid responses)\n- Test with long conversations (token limit handling)\n- Manual testing for UX feel\n\n**Implementation Hints:**\n```python\n@cli.command()\n@click.option('--model', help='Override model')\n@click.option('--no-stream', is_flag=True, help='Disable streaming')\n@click.option('--tools', help='Tool specification')\n@click.pass_context\ndef chat(\n    ctx: click.Context,\n    model: str | None,\n    no_stream: bool,\n    tools: str | None,\n) -> None:\n    \\\"\\\"\\\"Start an interactive chat session.\\\"\\\"\\\"\n    from consoul.cli.chat_session import ChatSession\n    \n    config = ctx.obj['config']\n    \n    # Apply CLI overrides\n    if model:\n        config.current_model = model\n    if tools:\n        # Parse and apply tools\n        pass\n    \n    console = Console()\n    console.print(Panel(\n        f\"Profile: {config.get_active_profile().name}\\n\"\n        f\"Model: {config.current_provider.value}/{config.current_model}\",\n        title=\"Consoul Chat\",\n        border_style=\"cyan\"\n    ))\n    console.print(\"Type 'exit' or press Ctrl+D to quit\\n\")\n    \n    with ChatSession(config) as session:\n        # Main chat loop\n        while True:\n            try:\n                user_input = session.get_input()\n                if not user_input:\n                    continue\n                \n                response = session.send(\n                    user_input,\n                    stream=not no_stream\n                )\n                \n            except (EOFError, KeyboardInterrupt):\n                break\n        \n        # Show stats\n        console.print(f\"\\nMessages: {len(session.history)}\")\n        console.print(f\"Tokens: {session.history.count_tokens()}\")\n```\n\nDependencies:\n- SOUL-165 (prompt_toolkit)\n- SOUL-166 (ChatSession)  \n- SOUL-167 (Markdown rendering)\n- SOUL-168 (Enhanced input)\n- SOUL-169 (Tool calls)",
  "status": "done",
  "type": "feature",
  "priority": "high",
  "labels": [
    "cli",
    "ai",
    "enhancement"
  ],
  "assignee": "jared@goatbytes.io",
  "reporter": "jared@goatbytes.io",
  "blocked_by": [],
  "blocks": [],
  "comments": [],
  "attachments": [],
  "attachment_count": 0,
  "comment_count": 0,
  "story_points": 8,
  "order": 0,
  "custom_fields": {}
}