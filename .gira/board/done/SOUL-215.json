{
  "created_at": "2025-12-02T18:07:20.333628",
  "updated_at": "2025-12-02T18:14:40.264748",
  "id": "SOUL-215",
  "uuid": "801ab755-1fa2-4406-a54a-4704239d382a",
  "title": "Fix ConversationHistory token limit initialization tests",
  "description": "**As a** Consoul developer\n**I want** ConversationHistory token limit tests to pass\n**So that** we can ensure correct token management behavior\n\n**Context:**\nThree tests in tests/ai/test_history.py are failing due to a mismatch between expected and actual token limits. Tests expect 128000 tokens for gpt-4o, but the implementation applies a 0.75 multiplier (resulting in 96000) when max_tokens is None or 0.\n\nRoot cause: src/consoul/ai/history.py:247-249 applies a 0.75 safety margin by default.\n\n**Technical Notes:**\n- src/consoul/ai/history.py:247-249 - Default token limit calculation\n- src/consoul/ai/context.py:222 - gpt-4o model limit is 128000\n- tests/ai/test_history.py:88 - Failing assertion expects 128000\n\n**Acceptance Criteria:**\n\n**Given** a ConversationHistory is initialized with \"gpt-4o\" and no max_tokens\n**When** the token limit is checked\n**Then** it should match the documented behavior\n\n**Given** custom trimming strategies are used\n**When** messages are trimmed\n**Then** the strategy should respect the actual max_tokens value\n\n**Testing Considerations:**\n- Verify all 3 failing tests pass\n- Ensure token limit calculation is consistent\n\n**Implementation Hints:**\n- Option 1: Update tests to expect 96000 (75% of 128000)\n- Option 2: Remove 0.75 multiplier and use full model limit\n- Option 3: Make the safety margin configurable\n\n**Failing Tests:**\n- test_initialization_default_token_limit\n- test_get_trimmed_messages_custom_strategy\n- test_repr_shows_stats",
  "status": "done",
  "type": "bug",
  "priority": "high",
  "labels": [
    "testing",
    "bug",
    "ai",
    "core"
  ],
  "reporter": "jared@goatbytes.io",
  "parent_id": "SOUL-214",
  "blocked_by": [],
  "blocks": [],
  "comments": [
    {
      "created_at": "2025-12-02T18:14:40.264647",
      "updated_at": "2025-12-02T18:14:40.264649",
      "id": "20251202181440-173d6beb",
      "ticket_id": "SOUL-215",
      "author": "jared@goatbytes.io",
      "content": "Fixed the failing tests by updating test expectations to match the implementation's intentional 0.75 safety margin.\n\n## Analysis\nThe implementation in src/consoul/ai/history.py (lines 247-249) applies a 0.75 multiplier when max_tokens is None or 0, which is documented as a safety margin to prevent hitting exact context limits. This is intentional design.\n\n## Solution Chosen\nOption 1: Updated tests to expect 96,000 tokens (75% of 128,000) instead of removing the multiplier or making it configurable.\n\n## Changes Made\n1. test_initialization_default_token_limit: Changed expectation from 128,000 to 96,000\n2. test_get_trimmed_messages_custom_strategy: Changed max_tokens calculation from 128,000-500 to 96,000-500\n3. test_repr_shows_stats: Changed expected string from '128000' to '96000'\n\n## Test Results\n✅ All 3 failing tests now pass\n✅ All 34 tests in test_history.py pass with no regressions\n\n## Commit\n6b3f3ca - fix(SOUL-215): update test expectations for 0.75 token limit multiplier",
      "edited": false,
      "edit_count": 0,
      "is_ai_generated": false,
      "attachments": [],
      "attachment_count": 0
    }
  ],
  "attachments": [],
  "attachment_count": 0,
  "comment_count": 1,
  "story_points": 2,
  "order": 0,
  "custom_fields": {}
}