{
  "created_at": "2025-12-30T02:06:12.109853Z",
  "updated_at": "2025-12-31T03:23:17.263281Z",
  "id": "SOUL-332",
  "uuid": "1d53089f-a6b1-4ed3-a4d9-35e1b7d01c0f",
  "_version": 1,
  "title": "Add session garbage collection for Redis session store",
  "description": "**As a** production backend operator\n**I want** automatic garbage collection for Redis session storage\n**So that** orphaned sessions are proactively cleaned up to prevent memory growth even if Redis TTL is misconfigured\n\n**Context:**\nSessions stored in Redis via `RedisSessionStore` (src/consoul/sdk/session_store.py:679-942) rely on Redis TTL (`CONSOUL_SESSION_TTL`) for expiration. However:\n\n1. Redis TTL is set via `setex()` at line 777 - if TTL is `None`, sessions never expire\n2. Current `cleanup()` method (line 850-860) is a no-op returning 0 - assumes Redis handles everything\n3. No mechanism exists to proactively scan and clean orphaned sessions\n4. Memory could grow unbounded if:\n   - TTL is accidentally set to None/0\n   - Sessions accumulate faster than TTL expires\n   - Redis memory pressure causes eviction issues\n\n**Industry Patterns:**\n- FastAPI lifespan context manager for background task management (yield-based startup/shutdown)\n- `asyncio.create_task()` for periodic jobs with graceful cancellation\n- See existing patterns in `src/consoul/server/factory.py:214-268` (lifespan) and `src/consoul/server/endpoints/websocket.py:268-270` (background tasks)\n\n**Technical Notes:**\n- **Files to modify:**\n  - `src/consoul/server/models.py` - Add `gc_interval` to `SessionConfig` (line 535-570)\n  - `src/consoul/server/factory.py` - Add GC task to lifespan context (line 214-268)\n  - `src/consoul/sdk/session_store.py` - Implement actual `cleanup()` for Redis (line 850-860)\n\n- **SessionConfig additions:**\n  ```python\n  gc_interval: int = Field(\n      default=3600,  # 1 hour\n      description=\"Session GC interval in seconds (0 to disable)\",\n      validation_alias=\"CONSOUL_SESSION_GC_INTERVAL\",\n  )\n  gc_batch_size: int = Field(\n      default=100,  # Process 100 keys per SCAN iteration\n      description=\"Number of keys to process per GC batch\",\n      validation_alias=\"CONSOUL_SESSION_GC_BATCH_SIZE\",\n  )\n  ```\n\n- **GC Task Pattern (lifespan):**\n  ```python\n  async def session_gc_loop(store: SessionStore, interval: int) -> None:\n      while True:\n          await asyncio.sleep(interval)\n          try:\n              cleaned = store.cleanup()\n              if cleaned > 0:\n                  logger.info(f\"Session GC: cleaned {cleaned} orphaned sessions\")\n          except Exception as e:\n              logger.error(f\"Session GC failed: {e}\")\n\n  # In lifespan:\n  gc_task = None\n  if config.session.gc_interval > 0:\n      gc_task = asyncio.create_task(\n          session_gc_loop(session_store, config.session.gc_interval)\n      )\n  yield\n  if gc_task:\n      gc_task.cancel()\n      await asyncio.gather(gc_task, return_exceptions=True)\n  ```\n\n- **Redis cleanup() implementation:**\n  - Use SCAN (not KEYS) for production safety - already used in `list_sessions()` (line 897)\n  - Check each session's TTL with `redis.ttl(key)`\n  - Delete sessions with TTL=-1 (no expiry) that are older than `session.ttl`\n  - Log statistics: sessions scanned, sessions deleted, memory freed (via `redis.memory_usage()`)\n\n**Acceptance Criteria:**\n\n**Given** server starts with `CONSOUL_SESSION_GC_INTERVAL=3600` (default)\n**When** 1 hour passes\n**Then** GC task scans Redis for orphaned sessions and logs cleanup statistics\n\n**Given** server starts with `CONSOUL_SESSION_GC_INTERVAL=0`\n**When** server is running\n**Then** no GC background task is created (GC disabled)\n\n**Given** GC task runs and finds sessions without TTL (TTL=-1)\n**When** those sessions are older than `CONSOUL_SESSION_TTL`\n**Then** sessions are deleted and count is logged\n\n**Given** GC task runs\n**When** cleanup completes\n**Then** log includes: sessions scanned, sessions deleted, approximate memory freed\n\n**Given** server receives shutdown signal\n**When** GC task is running\n**Then** task is gracefully cancelled without error\n\n**Given** Redis is temporarily unavailable\n**When** GC task runs\n**Then** error is logged but task continues (does not crash server)\n\n**Testing Considerations:**\n- Unit test `cleanup()` with mock Redis client\n- Test SCAN iteration handles large keyspace (pagination)\n- Test graceful task cancellation in lifespan\n- Test GC interval=0 disables the task\n- Integration test with real Redis (if available in CI)\n- Verify no memory leaks in long-running GC loop\n- Test concurrent GC and session operations (no race conditions)\n\n**Implementation Hints:**\n- Follow existing `asyncio.create_task()` pattern from `websocket.py:270`\n- Use `redis.scan()` pattern from `list_sessions()` at line 897-918\n- Add `_gc_task` to `app.state` for testing/introspection\n- Consider adding metrics: `consoul_session_gc_runs_total`, `consoul_session_gc_cleaned_total`\n- Reference FastAPI lifespan documentation for task cancellation patterns\n- Test with `pytest-asyncio` for async test coverage\n\n**Dependencies:**\n- Builds on EPIC-019 session management infrastructure\n- Uses existing `SessionStore.cleanup()` protocol method (line 140-149)\n\n**Out of Scope:**\n- Memory-based store GC (already has cleanup implementation at line 304-326)\n- File-based store GC (already has cleanup implementation at line 572-612)\n- Cross-node session coordination (single-node GC only)",
  "status": "done",
  "type": "feature",
  "priority": "medium",
  "labels": [
    "server",
    "sessions",
    "redis",
    "performance"
  ],
  "assignee": "jared@goatbytes.io",
  "reporter": "jared@goatbytes.io",
  "epic_id": "EPIC-019",
  "blocked_by": [],
  "blocks": [],
  "comments": [],
  "attachments": [],
  "attachment_count": 0,
  "comment_count": 0,
  "story_points": 3,
  "order": 0,
  "custom_fields": {}
}