{
  "created_at": "2025-12-31T05:23:48.966392Z",
  "updated_at": "2026-01-01T01:52:11.038943Z",
  "id": "SOUL-345",
  "uuid": "a3541489-1555-44ce-9ba2-788abfd63193",
  "_version": 1,
  "title": "Add load testing guide with benchmarks",
  "description": "**As a** DevOps engineer validating Consoul performance\n**I want** a comprehensive load testing guide with example scripts and baseline benchmarks\n**So that** I can validate my deployment meets performance requirements\n\n**Context:**\nThere is no documented approach for load testing Consoul. Before production deployment, operators need to:\n- Establish baseline performance metrics\n- Identify bottlenecks under load\n- Validate scaling behavior\n- Compare configurations\n\n**Technical Notes:**\n- HTTP endpoint: POST /chat (lines 686-806 in factory.py)\n- WebSocket: /ws/chat/{session_id} (websocket.py)\n- SSE endpoint: Proposed in SOUL-337\n- Metrics: Prometheus on port 9090 (`observability/metrics.py`)\n\n**Documentation Sections:**\n\n**1. Load Testing Tools**\n```bash\n# k6 (recommended - JavaScript-based)\nbrew install k6\n\n# Locust (Python-based alternative)\npip install locust\n\n# hey (simple HTTP load testing)\nbrew install hey\n```\n\n**2. k6 Test Script Example**\n```javascript\n// load_test.js\nimport http from 'k6/http';\nimport { check, sleep } from 'k6';\nimport { Rate } from 'k6/metrics';\n\nconst errorRate = new Rate('errors');\n\nexport const options = {\n  stages: [\n    { duration: '1m', target: 10 },   // Ramp up\n    { duration: '5m', target: 50 },   // Sustained load\n    { duration: '1m', target: 100 },  // Spike\n    { duration: '1m', target: 0 },    // Ramp down\n  ],\n  thresholds: {\n    http_req_duration: ['p(95)<2000'],  // 95th percentile < 2s\n    errors: ['rate<0.01'],               // Error rate < 1%\n  },\n};\n\nexport default function() {\n  const payload = JSON.stringify({\n    session_id: `load-test-${__VU}-${__ITER}`,\n    message: 'Hello, how are you?',\n  });\n\n  const params = {\n    headers: {\n      'Content-Type': 'application/json',\n      'X-API-Key': __ENV.API_KEY,\n    },\n  };\n\n  const res = http.post('http://localhost:8000/chat', payload, params);\n  \n  check(res, {\n    'status is 200': (r) => r.status === 200,\n    'response has content': (r) => r.json().response !== undefined,\n  }) || errorRate.add(1);\n\n  sleep(1);\n}\n```\n\n**3. WebSocket Load Test**\n```javascript\n// ws_load_test.js\nimport ws from 'k6/ws';\nimport { check } from 'k6';\n\nexport default function() {\n  const url = 'ws://localhost:8000/ws/chat/session-' + __VU;\n  \n  const res = ws.connect(url, {}, function(socket) {\n    socket.on('open', () => {\n      socket.send(JSON.stringify({\n        type: 'message',\n        content: 'Hello from load test',\n      }));\n    });\n    \n    socket.on('message', (data) => {\n      const msg = JSON.parse(data);\n      if (msg.type === 'done') {\n        socket.close();\n      }\n    });\n    \n    socket.setTimeout(function() {\n      socket.close();\n    }, 10000);\n  });\n  \n  check(res, { 'status is 101': (r) => r && r.status === 101 });\n}\n```\n\n**4. Baseline Benchmarks**\nDocument expected performance on reference hardware:\n- Single node (4 CPU, 8GB RAM, Redis):\n  - HTTP /chat: 50 req/s @ p95 < 500ms (without LLM call)\n  - WebSocket: 100 concurrent connections\n  - With mock LLM: 200 req/s @ p95 < 100ms\n\n**5. Metrics to Monitor**\n```prometheus\n# Key metrics during load test\nconsoul_http_request_duration_seconds{path=\"/chat\"}\nconsoul_active_websocket_connections\nconsoul_tokens_total{type=\"input|output\"}\nconsoul_circuit_breaker_state{provider=\"*\"}\n```\n\n**6. Interpreting Results**\n- Latency breakdown: server vs LLM vs Redis\n- Saturation indicators: queue depth, connection pool exhaustion\n- Error patterns: rate limits, timeouts, circuit breaker trips\n\n**Acceptance Criteria:**\n\n**Given** load testing documentation exists\n**When** running the example k6 script\n**Then** valid load test results are produced\n\n**Given** WebSocket load test script exists\n**When** testing concurrent connections\n**Then** connection limits and behavior are measured\n\n**Given** baseline benchmarks are documented\n**When** comparing to my deployment\n**Then** I can identify if my setup is underperforming\n\n**Given** metrics monitoring guide exists\n**When** running a load test\n**Then** I can identify bottlenecks in real-time\n\n**Testing Considerations:**\n- Run benchmarks on standardized hardware\n- Include both real LLM and mock LLM numbers\n- Test with Redis and without (in-memory)\n- Document reproducible test conditions\n\n**Implementation Hints:**\n- Create `docs/testing/load-testing.md`\n- Add `scripts/load-test/` directory with k6 scripts\n- Include `docker-compose.test.yml` for isolated testing\n- Reference grafana-k6 for result visualization\n- Cross-reference with performance tuning guide (SOUL-344)\n- Consider adding load test to CI (lightweight smoke test)",
  "status": "done",
  "type": "task",
  "priority": "medium",
  "labels": [
    "documentation",
    "testing",
    "performance",
    "server"
  ],
  "reporter": "jared@goatbytes.io",
  "epic_id": "EPIC-021",
  "blocked_by": [],
  "blocks": [],
  "comments": [],
  "attachments": [],
  "attachment_count": 0,
  "comment_count": 0,
  "story_points": 5,
  "order": 0,
  "custom_fields": {}
}