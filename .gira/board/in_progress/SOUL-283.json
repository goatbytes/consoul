{
  "created_at": "2025-12-15T20:23:32.791524",
  "updated_at": "2025-12-16T04:30:39.232757Z",
  "id": "SOUL-283",
  "uuid": "25d050e6-18e2-4805-a3c3-362d2f947942",
  "title": "Refactor thinking mode detection to SDK layer for headless usage",
  "description": "**As a** SDK user (FastAPI, WebSocket, CLI, web UI developer)\n**I want** thinking mode detection and extraction in the SDK layer\n**So that** I can handle reasoning model responses programmatically without TUI dependencies\n\n**Context:**\nCurrently, thinking mode logic is embedded in the TUI layer (StreamingOrchestrator, StreamingResponse, ThinkingIndicator). This violates EPIC-012's SDK-first architecture goal and prevents headless SDK usage from handling reasoning models (DeepSeek-R1, Qwen QWQ, o1-preview) that output chain-of-thought in XML tags like <think>...</think>.\n\nThe refactoring completed in commit c5e8849 restored v0.2.0 thinking mode support, but it's coupled to TUI widgets. For SDK users to build FastAPI endpoints, web UIs, or CLI tools, they need access to structured thinking content without instantiating Textual widgets.\n\n**Current Architecture (TUI-coupled):**\n- StreamingResponse.detect_thinking_start() - Widget method\n- StreamingResponse.detect_thinking_end() - Widget method  \n- StreamingResponse.thinking_buffer - Widget property\n- ThinkingIndicator - TUI widget for display\n- StreamingOrchestrator.stream_message() - TUI service with detection logic\n\n**Target Architecture (SDK-first):**\nSDK Layer (src/consoul/sdk/):\n├── models.py - Add ThinkingContent dataclass\n└── thinking.py (NEW) - ThinkingDetector class\n\nTUI Layer (src/consoul/tui/):\n├── widgets/thinking_indicator.py (presentation only)\n└── services/streaming_orchestrator.py (uses SDK's ThinkingDetector)\n\n**Technical Notes:**\n- Create src/consoul/sdk/thinking.py module (~100 lines)\n- Add ThinkingContent dataclass to src/consoul/sdk/models.py\n- Extract detection logic from src/consoul/tui/widgets/streaming_response.py:254-277\n- Update StreamingOrchestrator to use SDK's ThinkingDetector\n- Move regex patterns to SDK (support <think>, <thinking>, <reasoning>)\n- Enable ConversationService.send_message() to yield structured metadata\n\n**Acceptance Criteria:**\n\nGiven I'm using the headless SDK in a FastAPI app\nWhen I call conversation_service.send_message() with a reasoning model\nThen I receive Token objects with metadata={\"is_thinking\": True} during thinking phase\n\nGiven I'm using the SDK to extract thinking content\nWhen I call ThinkingDetector.extract(full_response)\nThen I get a ThinkingContent object with separated thinking and answer fields\n\nGiven I'm building a web UI using the SDK\nWhen DeepSeek-R1 streams a response with <think> tags\nThen I can detect thinking start/end and route content appropriately without importing TUI widgets\n\nGiven the existing TUI still works after refactoring\nWhen I run Consoul with a reasoning model\nThen the ThinkingIndicator still displays correctly using SDK's detection logic\n\n**Testing Considerations:**\n- Unit tests for ThinkingDetector with various tag formats\n- Test extraction with nested tags, malformed XML\n- Test edge cases (no closing tag, empty thinking, thinking-only response)\n- Verify TUI integration tests still pass\n- Test SDK usage in isolation (no TUI imports)\n\n**Benefits:**\n- SDK users can build FastAPI endpoints: POST /chat → {\"thinking\": \"...\", \"answer\": \"...\"}\n- Web UI developers can display thinking with custom components\n- CLI tools can show thinking as dimmed text or separate output\n- Testable in isolation (no Textual dependencies)\n- Aligns with EPIC-012 SDK-first architecture\n- Enables EPIC-011 (WebSocket/FastAPI backend) to provide structured responses",
  "status": "in_progress",
  "type": "feature",
  "priority": "medium",
  "labels": [
    "sdk",
    "refactor",
    "ai",
    "reasoning-models",
    "epic-012"
  ],
  "reporter": "jared@goatbytes.io",
  "epic_id": "EPIC-012",
  "blocked_by": [],
  "blocks": [],
  "comments": [],
  "attachments": [],
  "attachment_count": 0,
  "comment_count": 0,
  "story_points": 5,
  "order": 0,
  "custom_fields": {}
}