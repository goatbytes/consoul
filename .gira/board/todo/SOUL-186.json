{
  "created_at": "2025-11-29T08:25:26.007146",
  "updated_at": "2025-11-29T16:40:37.006537Z",
  "id": "SOUL-186",
  "uuid": "de56db36-3ba4-4825-b9ff-e8dcaab3ea88",
  "title": "Add prompt caching cost tracking for Anthropic models",
  "description": "## Problem\nAnthropic's prompt caching significantly affects costs but is not tracked separately:\n- Cache write tokens cost 1.25x-2x base price (5-min vs 1-hour cache)\n- Cache read tokens cost only 0.1x base price\n- Current implementation doesn't distinguish cached vs uncached tokens\n\n## Solution\nTrack prompt caching costs using `input_token_details` from `usage_metadata`.\n\n## Anthropic Cache Pricing\n\n### Cache Write Tokens\n- **5-minute cache**: 1.25x input token price\n- **1-hour cache**: 2x input token price\n\n### Cache Read Tokens\n- **Cached reads**: 0.1x input token price (90% discount!)\n\n## Implementation\n\n### 1. Extract Cache Details from Usage Metadata\n\n```python\n# Anthropic populates these fields via _create_usage_metadata\nif response.usage_metadata:\n    input_token_details = response.usage_metadata.get('input_token_details', {})\n    \n    cache_read = input_token_details.get('cache_read', 0)\n    cache_creation = input_token_details.get('cache_creation', 0)\n    cache_5m = input_token_details.get('ephemeral_5m_input_tokens', 0)\n    cache_1h = input_token_details.get('ephemeral_1h_input_tokens', 0)\n```\n\n### 2. Calculate Cache-Aware Costs\n\n```python\ndef calculate_anthropic_cost(\n    base_input_tokens: int,\n    output_tokens: int,\n    cache_read_tokens: int,\n    cache_write_5m_tokens: int,\n    cache_write_1h_tokens: int,\n    model_name: str\n) -> dict:\n    pricing = get_model_pricing(model_name)\n    \n    # Base input cost (non-cached tokens)\n    base_cost = (base_input_tokens / 1_000_000) * pricing.input_cost_per_million\n    \n    # Cache read cost (90% discount!)\n    cache_read_cost = (cache_read_tokens / 1_000_000) * pricing.input_cost_per_million * 0.1\n    \n    # Cache write costs\n    cache_5m_cost = (cache_write_5m_tokens / 1_000_000) * pricing.input_cost_per_million * 1.25\n    cache_1h_cost = (cache_write_1h_tokens / 1_000_000) * pricing.input_cost_per_million * 2.0\n    \n    # Output cost (unchanged)\n    output_cost = (output_tokens / 1_000_000) * pricing.output_cost_per_million\n    \n    total_cost = base_cost + cache_read_cost + cache_5m_cost + cache_1h_cost + output_cost\n    \n    return {\n        'input_tokens': base_input_tokens,\n        'output_tokens': output_tokens,\n        'cache_read_tokens': cache_read_tokens,\n        'cache_write_5m_tokens': cache_write_5m_tokens,\n        'cache_write_1h_tokens': cache_write_1h_tokens,\n        'cost_breakdown': {\n            'base_input': base_cost,\n            'cache_read': cache_read_cost,\n            'cache_write_5m': cache_5m_cost,\n            'cache_write_1h': cache_1h_cost,\n            'output': output_cost,\n        },\n        'total_cost_usd': total_cost,\n        'cache_savings_usd': (cache_read_tokens / 1_000_000) * pricing.input_cost_per_million * 0.9,\n    }\n```\n\n### 3. Update last_cost Property\n\n```python\n@property\ndef last_cost(self) -> dict[str, Any]:\n    # ... get usage_metadata ...\n    \n    # Check if this is an Anthropic model with cache details\n    if 'claude' in self.model_name.lower():\n        input_details = metadata.get('input_token_details', {})\n        if input_details:\n            return self._calculate_anthropic_cost_with_cache(\n                metadata, input_details\n            )\n    \n    # Fallback to standard cost calculation\n    return self._calculate_standard_cost(metadata)\n```\n\n## Benefits\n\n1. **Accurate cost tracking**: Reflect actual cached vs uncached token costs\n2. **Cache savings visibility**: Show how much users save with prompt caching\n3. **Optimization insights**: Help users understand cache effectiveness\n\n## Example Output\n\n```python\nconsole.last_cost\n# {\n#     'input_tokens': 1000,\n#     'output_tokens': 500,\n#     'cache_read_tokens': 8000,  # 90% discount!\n#     'cache_write_5m_tokens': 0,\n#     'cache_write_1h_tokens': 0,\n#     'cost_breakdown': {\n#         'base_input': 0.003,      # 1000 tokens @ $3/M\n#         'cache_read': 0.0024,     # 8000 tokens @ $0.30/M (90% off)\n#         'output': 0.0075,         # 500 tokens @ $15/M\n#     },\n#     'total_cost_usd': 0.0129,\n#     'cache_savings_usd': 0.0216,  # Saved 90% on 8K tokens!\n#     'model': 'claude-3-5-sonnet-20241022'\n# }\n```\n\n## Testing\n\n- Test with Anthropic responses containing cache details\n- Test cache read savings calculation\n- Test 5-min vs 1-hour cache write pricing\n- Test fallback for models without cache support\n\n## References\n- Anthropic Prompt Caching: https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching\n- LangChain `_create_usage_metadata`: Handles cache token extraction\n- Cache pricing structure in Anthropic docs",
  "status": "todo",
  "type": "feature",
  "priority": "medium",
  "labels": [],
  "assignee": "jared@goatbytes.io",
  "reporter": "jared@goatbytes.io",
  "blocked_by": [],
  "blocks": [],
  "comments": [],
  "attachments": [],
  "attachment_count": 0,
  "comment_count": 0,
  "order": 0,
  "custom_fields": {}
}