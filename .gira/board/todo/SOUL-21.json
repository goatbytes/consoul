{
  "created_at": "2025-11-08T16:29:04.062576",
  "updated_at": "2025-11-08T16:29:04.062587",
  "id": "SOUL-21",
  "uuid": "d6e43385-04a8-4156-995e-7f0d6dbd9b3b",
  "title": "Implement OpenAI provider support",
  "description": "## User Story\nAs a Consoul user, I want to use OpenAI's GPT models so that I can leverage the most widely-used commercial LLM service.\n\n## Description\nImplement full support for OpenAI's chat models using LangChain's `ChatOpenAI` integration. Support all major GPT models including GPT-4o, GPT-4 Turbo, and GPT-3.5 Turbo with OpenAI-specific parameters and streaming capabilities.\n\n## Technical Notes\n- **File**: `src/consoul/ai/providers/openai.py`\n- **LangChain Docs**: https://python.langchain.com/docs/integrations/chat/openai/\n- **Package**: `langchain-openai`\n- **Environment Variable**: `OPENAI_API_KEY`\n- Supported models: gpt-4o, gpt-4-turbo, gpt-4, gpt-3.5-turbo\n- OpenAI-specific params: frequency_penalty, presence_penalty, logit_bias, seed\n- Streaming support via `.stream()`\n\n## Acceptance Criteria\n- **Given** a valid OPENAI_API_KEY\n- **When** user specifies an OpenAI model\n- **Then** the model is initialized with correct parameters\n\n- **Given** OpenAI-specific parameters (frequency_penalty, presence_penalty)\n- **When** creating the chat model\n- **Then** these parameters are passed to the OpenAI API\n\n- **Given** a streaming request\n- **When** generating a response\n- **Then** tokens are yielded one at a time\n\n- **Given** missing langchain-openai package\n- **When** attempting to use OpenAI\n- **Then** error suggests: `pip install langchain-openai`\n\n## Testing Considerations\n- Mock OpenAI API responses\n- Test model parameter validation\n- Verify streaming functionality\n- Test error handling for invalid API keys\n- Mock missing package import\n\n## Implementation Hints\n```python\nfrom langchain_openai import ChatOpenAI\n\ndef create_openai_model(\n    model: str = \"gpt-4o\",\n    temperature: float = 0.7,\n    streaming: bool = False,\n    **kwargs\n):\n    \"\"\"Create OpenAI chat model.\"\"\"\n    return ChatOpenAI(\n        model=model,\n        temperature=temperature,\n        streaming=streaming,\n        **kwargs\n    )\n```\n\n## Dependencies\n- SOUL-20 (provider initialization)\n\n## Story Points\n3 - Straightforward integration with existing LangChain support",
  "status": "todo",
  "type": "feature",
  "priority": "high",
  "labels": [
    "ai",
    "providers",
    "openai"
  ],
  "reporter": "jared@goatbytes.io",
  "epic_id": "EPIC-002",
  "blocked_by": [],
  "blocks": [],
  "comments": [],
  "attachments": [],
  "attachment_count": 0,
  "comment_count": 0,
  "story_points": 3,
  "order": 0,
  "custom_fields": {}
}