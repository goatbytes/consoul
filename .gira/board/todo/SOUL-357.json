{
  "created_at": "2026-01-01T10:45:42.175729Z",
  "updated_at": "2026-01-01T22:33:47.442359Z",
  "id": "SOUL-357",
  "uuid": "59e376e0-e4bc-480b-8503-70faa7bb4a83",
  "_version": 2,
  "title": "Increase test coverage from 15.19% to 30%",
  "description": "**As a** Consoul maintainer\n**I want** test coverage to increase from 15.19% to 30%\n**So that** critical production code paths are verified and regressions are caught early\n\n**Context:**\nCurrent test coverage stands at 15.19% with 3,201 tests collecting against 21,443 lines of code (17,199 lines hit, 6,664 missing). To reach 30% coverage, approximately 3,181 additional lines need to be covered (from 14,779 to ~6,433 uncovered lines).\n\nAnalysis of the codebase reveals several critical modules with insufficient coverage that should be prioritized:\n\n**Priority Areas (by criticality and line count):**\n\n1. **`src/consoul/server/`** (~14,600 lines)\n   - `factory.py` (1,388 lines) - FastAPI app factory, middleware setup\n   - `models.py` (1,309 lines) - Request/response models, validation\n   - `webhooks/store.py` (685 lines) - Webhook persistence layer\n   - `observability/metrics.py` (673 lines) - Prometheus metrics\n   - `endpoints/websocket.py` (612 lines) - WebSocket handler\n   - Existing tests cover ~7,188 lines but core error paths need more coverage\n\n2. **`src/consoul/ai/providers.py`** (~2,066 lines)\n   - Provider factory pattern with 7 providers (OpenAI, Anthropic, Google, Ollama, HuggingFace, LlamaCpp, MLX)\n   - Complex model detection logic (get_provider_from_model)\n   - API key resolution from multiple sources\n   - GGUF/MLX model scanning and caching\n   - Existing `tests/ai/test_providers.py` (2,096 lines) covers happy paths; edge cases needed\n\n3. **`src/consoul/sdk/`** (~14,262 lines)\n   - `wrapper.py` (1,662 lines) - Main SDK wrapper, primary public API\n   - `services/conversation.py` (1,464 lines) - Conversation management\n   - `services/model.py` (1,147 lines) - Model service layer\n   - `session_store.py` (1,237 lines) - Session persistence implementations\n   - Existing SDK tests (~13,794 lines) but gaps in wrapper.py and edge cases\n\n4. **`src/consoul/ai/tools/implementations/`** (~6,065 lines)\n   - `file_edit.py` (1,699 lines) - File editing tool, security-critical\n   - `read.py` (653 lines) - File reading tool\n   - `find_references.py` (608 lines) - Code reference finding\n   - `web_search.py` (509 lines) - Web search integration\n   - Security-sensitive tools need comprehensive edge case coverage\n\n**Technical Notes:**\n- Use pytest fixtures from `tests/conftest.py` for shared test setup\n- Mock LangChain providers using `unittest.mock` to avoid API calls\n- Use `pytest-asyncio` for async endpoint testing\n- Follow existing test patterns in `tests/server/test_factory.py` and `tests/ai/test_providers.py`\n- Focus on unit tests first (faster feedback), then integration tests\n- Use `httpx.AsyncClient` for FastAPI endpoint testing (see `tests/server/test_chat_endpoint.py`)\n\n**Acceptance Criteria:**\n\n**Given** the current test suite with 15.19% coverage\n**When** I run `pytest --cov=src/consoul --cov-report=term-missing`\n**Then** the overall coverage should be at least 30%\n\n**Given** the server module\n**When** I examine the coverage report for `src/consoul/server/`\n**Then** factory.py should have >50% coverage\n**And** models.py should have >40% coverage\n**And** all middleware modules should have >60% coverage\n\n**Given** the AI providers module\n**When** I examine the coverage for `src/consoul/ai/providers.py`\n**Then** coverage should be >50%\n**And** all provider detection paths should be tested\n**And** API key resolution from config, env, and explicit should be tested\n**And** Ollama service availability checks should be tested with mocks\n\n**Given** the SDK wrapper\n**When** I examine the coverage for `src/consoul/sdk/wrapper.py`\n**Then** coverage should be >40%\n**And** all public methods should have at least one test case\n\n**Given** the AI tools implementations\n**When** I examine coverage for `src/consoul/ai/tools/implementations/`\n**Then** file_edit.py should have >45% coverage\n**And** read.py should have >50% coverage\n**And** error handling paths should be tested for security-critical tools\n\n**Testing Considerations:**\n- **Mocking Strategy**: Use `unittest.mock.patch` to mock:\n  - LangChain model initialization (ChatOpenAI, ChatAnthropic, etc.)\n  - External HTTP calls (requests, httpx)\n  - Ollama service checks (is_ollama_running)\n  - File system operations for tool tests\n- **Async Testing**: Use `pytest.mark.asyncio` for async functions\n- **Fixtures**: Create reusable fixtures for:\n  - Mock ConsoulConfig objects\n  - Mock LangChain models with predictable responses\n  - Temporary file structures for file operation tests\n  - Mock Redis/session stores\n- **Edge Cases to Cover**:\n  - Provider initialization failures (missing deps, invalid models)\n  - API key resolution precedence (explicit > config > env)\n  - Rate limiting and circuit breaker states\n  - Session store edge cases (concurrent access, corruption)\n  - Tool execution timeouts and cancellation\n\n**Implementation Hints:**\n1. Start with `src/consoul/ai/providers.py` - highest value for effort ratio\n   - Add tests for `get_provider_from_model()` edge cases (Ollama colons, HuggingFace slashes)\n   - Test `get_chat_model()` with mocked LangChain classes\n   - Test GGUF/MLX model scanning with mock file systems\n\n2. Expand `tests/server/` coverage\n   - Add tests for error response formatting in `errors.py`\n   - Test middleware chain in `factory.py` with various configurations\n   - Add webhook delivery and retry logic tests\n\n3. Add `tests/sdk/test_wrapper.py`\n   - Test `ConsoulWrapper` initialization with various configs\n   - Test `chat()` method with mocked conversation service\n   - Test streaming response handling\n\n4. Expand tool implementation tests\n   - Reference existing `tests/ai/tools/implementations/test_file_edit.py` patterns\n   - Add boundary condition tests (empty files, large files, binary files)\n   - Test permission validation and sandboxing\n\n**Files to Create:**\n- `tests/ai/test_providers_edge_cases.py` - Additional provider edge cases\n- `tests/sdk/test_wrapper.py` - ConsoulWrapper unit tests\n- `tests/server/test_errors.py` - Error handling tests\n- `tests/server/webhooks/test_delivery.py` - Webhook delivery tests\n\n**Files to Expand:**\n- `tests/ai/test_providers.py` - Add mock-based provider tests\n- `tests/server/test_factory.py` - Add middleware chain tests\n- `tests/ai/tools/implementations/test_read_url.py` - Add SSRF/timeout tests\n\n**References:**\n- pytest-cov documentation: https://pytest-cov.readthedocs.io/\n- LangChain testing patterns: https://python.langchain.com/docs/contributing/testing\n- FastAPI testing guide: https://fastapi.tiangolo.com/tutorial/testing/",
  "status": "todo",
  "type": "task",
  "priority": "high",
  "labels": [
    "testing",
    "quality",
    "technical-debt",
    "core",
    "ai",
    "server",
    "sdk"
  ],
  "assignee": "jared@goatbytes.io",
  "reporter": "jared@goatbytes.io",
  "blocked_by": [],
  "blocks": [],
  "comments": [],
  "attachments": [],
  "attachment_count": 0,
  "comment_count": 0,
  "story_points": 13,
  "order": 0,
  "custom_fields": {}
}