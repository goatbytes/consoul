2025-11-19 18:01:05,892 - consoul.tui.cli - INFO - Debug logging enabled, writing to: ./log.txt
2025-11-19 18:01:09,302 - consoul.tui.app - INFO - [TIMING] Message submit handler started
2025-11-19 18:01:09,302 - consoul.tui.app - INFO - [TIMING] Model check complete: 0.2ms
2025-11-19 18:01:09,302 - consoul.tui.app - INFO - [TIMING] Reset tracking: 0.1ms
2025-11-19 18:01:09,313 - consoul.tui.app - INFO - [TIMING] Added message bubble: 10.7ms
2025-11-19 18:01:09,315 - consoul.tui.app - INFO - [TIMING] Added typing indicator: 2.4ms
2025-11-19 18:01:09,315 - consoul.tui.app - INFO - [TIMING] Starting background processing: 0.0ms
2025-11-19 18:01:09,316 - consoul.tui.app - INFO - [TIMING] Worker started: 13.5ms from submit
2025-11-19 18:01:09,316 - consoul.tui.app - INFO - [TIMING] Message handler exiting, worker launched: 13.5ms
2025-11-19 18:01:09,320 - consoul.tui.app - INFO - Created conversation session: 98a55ae9-642d-4a2b-b678-cb9e6bd52217
2025-11-19 18:01:09,326 - consoul.tui.app - INFO - [TIMING] DB persist complete: 9.9ms
2025-11-19 18:01:09,326 - consoul.tui.app - INFO - [TIMING] About to call _stream_ai_response
2025-11-19 18:01:09,326 - consoul.tui.app - INFO - [TIMING] _stream_ai_response ENTRY
2025-11-19 18:01:09,326 - consoul.tui.app - DEBUG - [TOOL_FLOW] _stream_ai_response ENTRY - iteration 0/5
2025-11-19 18:01:09,326 - consoul.tui.app - INFO - [TIMING] Updated streaming state: 0.2ms
2025-11-19 18:01:09,326 - consoul.tui.app - INFO - [TIMING] Got model config: 0.0ms
2025-11-19 18:01:09,328 - consoul.tui.app - INFO - [TIMING] Got trimmed messages: 1.9ms
2025-11-19 18:01:09,328 - consoul.tui.app - INFO - [TIMING] Converted to dict: 0.4ms, total prep: 2.6ms
2025-11-19 18:01:15,658 - consoul.tui.app - DEBUG - [TOOL_FLOW] Got first_token: is_none=False, value=Hello
2025-11-19 18:01:15,663 - consoul.tui.widgets.streaming_response - DEBUG - add_token: buffer_size=5, time_since=1763604075664ms, total_len=5
2025-11-19 18:01:15,663 - consoul.tui.widgets.streaming_response - DEBUG - Rendering full content as markdown: 5 chars
2025-11-19 18:01:15,682 - consoul.tui.widgets.streaming_response - DEBUG - add_token: buffer_size=1, time_since=18ms, total_len=6
2025-11-19 18:01:15,705 - consoul.tui.widgets.streaming_response - DEBUG - add_token: buffer_size=5, time_since=42ms, total_len=10
2025-11-19 18:01:15,730 - consoul.tui.widgets.streaming_response - DEBUG - add_token: buffer_size=9, time_since=66ms, total_len=14
2025-11-19 18:01:15,754 - consoul.tui.widgets.streaming_response - DEBUG - add_token: buffer_size=11, time_since=91ms, total_len=16
2025-11-19 18:01:15,778 - consoul.tui.widgets.streaming_response - DEBUG - add_token: buffer_size=18, time_since=115ms, total_len=23
2025-11-19 18:01:15,802 - consoul.tui.widgets.streaming_response - DEBUG - add_token: buffer_size=22, time_since=139ms, total_len=27
2025-11-19 18:01:15,826 - consoul.tui.widgets.streaming_response - DEBUG - add_token: buffer_size=28, time_since=163ms, total_len=33
2025-11-19 18:01:15,827 - consoul.tui.widgets.streaming_response - DEBUG - Rendering full content as markdown: 33 chars
2025-11-19 18:01:15,850 - consoul.tui.widgets.streaming_response - DEBUG - add_token: buffer_size=1, time_since=24ms, total_len=34
2025-11-19 18:01:15,875 - consoul.tui.app - DEBUG - [TOOL_FLOW] Stream loop finished. Collected 11 chunks, exception=None
2025-11-19 18:01:15,875 - consoul.tui.app - DEBUG - Found 0 tool_calls after merging chunks
2025-11-19 18:01:15,875 - consoul.tui.app - DEBUG - Final tool_calls: []
2025-11-19 18:01:15,877 - consoul.tui.app - DEBUG - [TOOL_FLOW] Stream exception: None
2025-11-19 18:01:15,877 - consoul.tui.app - DEBUG - Final message has 0 tool_calls
2025-11-19 18:01:15,878 - consoul.tui.app - DEBUG - [TOOL_FLOW] About to send final_message to main thread
2025-11-19 18:01:15,878 - consoul.tui.app - DEBUG - [TOOL_FLOW] Sending final_message to queue: has_message=True
2025-11-19 18:01:15,878 - consoul.tui.app - DEBUG - [TOOL_FLOW] Got final_message from queue: type=AIMessage, is_none=False
2025-11-19 18:01:15,878 - consoul.tui.app - DEBUG - [TOOL_FLOW] Response check: has_content=Hello! How can I assist you today?, has_tool_calls_in_message=[], full_response_len=34, cancelled=False
2025-11-19 18:01:15,880 - consoul.tui.app - DEBUG - [TOOL_FLOW] Checking final_message for tool calls: has_final_message=True
2025-11-19 18:01:15,880 - consoul.tui.app - DEBUG - [TOOL_FLOW] Calling has_tool_calls()
2025-11-19 18:01:15,899 - consoul.tui.app - INFO - [TIMING] Worker complete: 6583.3ms, total: 6596.7ms
2025-11-19 18:01:25,955 - consoul.tui.app - INFO - [TIMING] Message submit handler started
2025-11-19 18:01:25,956 - consoul.tui.app - INFO - [TIMING] Model check complete: 0.2ms
2025-11-19 18:01:25,956 - consoul.tui.app - INFO - [TIMING] Reset tracking: 0.1ms
2025-11-19 18:01:25,966 - consoul.tui.app - INFO - [TIMING] Added message bubble: 10.5ms
2025-11-19 18:01:25,970 - consoul.tui.app - INFO - [TIMING] Added typing indicator: 3.9ms
2025-11-19 18:01:25,970 - consoul.tui.app - INFO - [TIMING] Starting background processing: 0.1ms
2025-11-19 18:01:25,970 - consoul.tui.app - INFO - [TIMING] Worker started: 14.9ms from submit
2025-11-19 18:01:25,970 - consoul.tui.app - INFO - [TIMING] Message handler exiting, worker launched: 15.0ms
2025-11-19 18:01:25,974 - consoul.tui.app - INFO - [TIMING] DB persist complete: 3.6ms
2025-11-19 18:01:25,974 - consoul.tui.app - INFO - [TIMING] About to call _stream_ai_response
2025-11-19 18:01:25,974 - consoul.tui.app - INFO - [TIMING] _stream_ai_response ENTRY
2025-11-19 18:01:25,974 - consoul.tui.app - DEBUG - [TOOL_FLOW] _stream_ai_response ENTRY - iteration 0/5
2025-11-19 18:01:25,974 - consoul.tui.app - INFO - [TIMING] Updated streaming state: 0.4ms
2025-11-19 18:01:25,975 - consoul.tui.app - INFO - [TIMING] Got model config: 0.1ms
2025-11-19 18:01:25,975 - consoul.tui.app - INFO - [TIMING] Got trimmed messages: 0.5ms
2025-11-19 18:01:25,976 - consoul.tui.app - INFO - [TIMING] Converted to dict: 0.7ms, total prep: 1.7ms
2025-11-19 18:01:27,173 - consoul.tui.app - DEBUG - [TOOL_FLOW] Stream loop finished. Collected 3 chunks, exception=None
2025-11-19 18:01:27,173 - consoul.tui.app - DEBUG - Found 1 tool_calls after merging chunks
2025-11-19 18:01:27,174 - consoul.tui.app - DEBUG - Final tool_calls: [{'name': 'web_search', 'args': {'max_results': 3, 'query': 'speed limit on Interstate 5 freeway Los Angeles California'}, 'id': 'afb74f00-5a36-492f-abb6-38fbfdd01901', 'type': 'tool_call'}]
2025-11-19 18:01:27,174 - consoul.tui.app - DEBUG - Final message has 1 tool_calls
2025-11-19 18:01:27,174 - consoul.tui.app - DEBUG - [TOOL_FLOW] Got first_token: is_none=True, value=None
2025-11-19 18:01:27,174 - consoul.tui.app - DEBUG - [TOOL_FLOW] About to send final_message to main thread
2025-11-19 18:01:27,175 - consoul.tui.app - DEBUG - [TOOL_FLOW] Sending final_message to queue: has_message=True
2025-11-19 18:01:27,178 - consoul.tui.app - DEBUG - [TOOL_FLOW] Stream exception: None
2025-11-19 18:01:27,178 - consoul.tui.app - DEBUG - [TOOL_FLOW] Got final_message from queue: type=AIMessage, is_none=False
2025-11-19 18:01:27,178 - consoul.tui.app - DEBUG - [TOOL_FLOW] Response check: has_content=, has_tool_calls_in_message=[{'name': 'web_search', 'args': {'max_results': 3, 'query': 'speed limit on Interstate 5 freeway Los Angeles California'}, 'id': 'afb74f00-5a36-492f-abb6-38fbfdd01901', 'type': 'tool_call'}], full_response_len=0, cancelled=False
2025-11-19 18:01:27,185 - consoul.tui.app - DEBUG - [TOOL_FLOW] Checking final_message for tool calls: has_final_message=True
2025-11-19 18:01:27,185 - consoul.tui.app - DEBUG - [TOOL_FLOW] Calling has_tool_calls()
2025-11-19 18:01:27,185 - consoul.tui.app - DEBUG - [TOOL_FLOW] Tool calls detected in model response: 1 call(s), content_length=0
2025-11-19 18:01:27,185 - consoul.tui.app - DEBUG - [TOOL_FLOW] Replacing empty stream widget with tool execution message
2025-11-19 18:01:27,189 - consoul.tui.app - DEBUG - [TOOL_FLOW] Calling _handle_tool_calls with 1 calls
2025-11-19 18:01:27,189 - consoul.tui.app - DEBUG - [TOOL_FLOW] Tool call iteration 1 with 1 tool(s)
2025-11-19 18:01:27,189 - consoul.tui.app - DEBUG - [TOOL_FLOW] Reset tool results for new batch of 1 tools
2025-11-19 18:01:27,189 - consoul.tui.app - DEBUG - [TOOL_FLOW] Tool call detected: web_search with args: {'max_results': 3, 'query': 'speed limit on Interstate 5 freeway Los Angeles California'}
2025-11-19 18:01:27,189 - consoul.tui.app - DEBUG - [TOOL_FLOW] Posting ToolApprovalRequested for web_search
2025-11-19 18:01:27,189 - consoul.tui.app - DEBUG - [TOOL_FLOW] Posted ToolApprovalRequested for web_search
2025-11-19 18:01:27,189 - consoul.tui.app - DEBUG - [TOOL_FLOW] _handle_tool_calls completed
2025-11-19 18:01:27,189 - consoul.tui.app - INFO - [TIMING] Worker complete: 1218.8ms, total: 1233.8ms
2025-11-19 18:01:27,190 - consoul.tui.app - DEBUG - [TOOL_FLOW] on_tool_approval_requested called for web_search
2025-11-19 18:01:27,192 - consoul.tui.app - DEBUG - [TOOL_FLOW] Checking if approval needed for web_search
2025-11-19 18:01:27,192 - consoul.tui.app - DEBUG - [TOOL_FLOW] Approval check result: needs_approval=False
2025-11-19 18:01:27,192 - consoul.tui.app - DEBUG - [TOOL_FLOW] Auto-approving web_search
2025-11-19 18:01:27,197 - consoul.tui.app - DEBUG - [TOOL_FLOW] on_tool_approval_result: tool=web_search, approved=True, call_id=afb74f00-5a36-492f-abb6-38fbfdd01901
2025-11-19 18:01:27,198 - consoul.ai.tools.implementations.web_search - INFO - Using Jina Search for query: speed limit on Interstate 5 freeway Los Angeles California
